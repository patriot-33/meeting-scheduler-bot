"""
📈 POST-SOLUTION MONITORING SYSTEM
Continuous monitoring and health checks after solution implementation
"""

import asyncio
import time
import json
try:
    import schedule
except ImportError:
    schedule = None
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from threading import Thread, Event
from contextlib import contextmanager
import signal
import sys

from .core_diagnostics import DiagnosticLogger, diagnostic_context
from .system_monitor import SystemMonitor, DatabaseMonitor, ExternalServiceMonitor

class HealthStatus(Enum):
    """Health status levels"""
    HEALTHY = "HEALTHY"
    DEGRADED = "DEGRADED"
    CRITICAL = "CRITICAL"
    DOWN = "DOWN"

@dataclass
class HealthCheck:
    """Individual health check configuration"""
    name: str
    check_function: Callable[[], bool]
    interval_seconds: int
    timeout_seconds: int = 30
    critical: bool = True
    description: str = ""
    
@dataclass
class MonitoringAlert:
    """Alert generated by monitoring system"""
    timestamp: str
    alert_id: str
    severity: str  # INFO, WARNING, CRITICAL
    component: str
    message: str
    details: Dict[str, Any]
    resolved: bool = False
    resolution_timestamp: Optional[str] = None

@dataclass
class HealthReport:
    """Comprehensive health report"""
    timestamp: str
    overall_status: HealthStatus
    component_status: Dict[str, HealthStatus]
    active_alerts: List[MonitoringAlert]
    performance_metrics: Dict[str, Any]
    uptime_seconds: float
    last_restart: Optional[str] = None

class PostSolutionMonitor:
    """Comprehensive post-solution monitoring system"""
    
    def __init__(
        self, 
        logger: DiagnosticLogger,
        db_engine=None,
        alert_callback: Optional[Callable[[MonitoringAlert], None]] = None
    ):
        self.logger = logger
        self.db_engine = db_engine
        self.alert_callback = alert_callback
        
        # Monitoring components
        self.system_monitor = SystemMonitor(logger)
        self.db_monitor = DatabaseMonitor(logger, db_engine) if db_engine else None
        self.service_monitor = ExternalServiceMonitor(logger)
        
        # Health checks registry
        self.health_checks: Dict[str, HealthCheck] = {}
        self.active_alerts: List[MonitoringAlert] = []
        self.health_history: List[HealthReport] = []
        
        # Monitoring state
        self.monitoring_active = False
        self.monitoring_thread = None
        self.stop_event = Event()
        self.start_time = datetime.now(timezone.utc)
        
        # Default health checks
        self._register_default_health_checks()
    
    def _register_default_health_checks(self):
        """Register default health checks for meeting scheduler bot"""
        
        # System resource checks
        self.add_health_check(
            name="cpu_usage",
            check_function=lambda: self._check_cpu_usage(),
            interval_seconds=60,
            critical=True,
            description="Monitor CPU usage under 80%"
        )
        
        self.add_health_check(
            name="memory_usage", 
            check_function=lambda: self._check_memory_usage(),
            interval_seconds=60,
            critical=True,
            description="Monitor memory usage under 85%"
        )
        
        self.add_health_check(
            name="disk_space",
            check_function=lambda: self._check_disk_space(),
            interval_seconds=300,  # 5 minutes
            critical=True,
            description="Monitor disk space above 10% free"
        )
        
        # Database connectivity check
        if self.db_monitor:
            self.add_health_check(
                name="database_connectivity",
                check_function=lambda: self._check_database_health(),
                interval_seconds=120,  # 2 minutes
                critical=True,
                description="Verify database connectivity and response time"
            )
        
        # External service checks
        self.add_health_check(
            name="google_services",
            check_function=lambda: self._check_google_services(),
            interval_seconds=300,  # 5 minutes
            critical=False,
            description="Check Google Calendar API availability"
        )
        
        # Application-specific checks
        self.add_health_check(
            name="telegram_bot_responsive",
            check_function=lambda: self._check_telegram_bot_health(),
            interval_seconds=180,  # 3 minutes
            critical=True,
            description="Verify Telegram bot is responsive"
        )
    
    def add_health_check(
        self,
        name: str,
        check_function: Callable[[], bool],
        interval_seconds: int,
        critical: bool = True,
        description: str = "",
        timeout_seconds: int = 30
    ):
        """Add a custom health check"""
        
        health_check = HealthCheck(
            name=name,
            check_function=check_function,
            interval_seconds=interval_seconds,
            timeout_seconds=timeout_seconds,
            critical=critical,
            description=description
        )
        
        self.health_checks[name] = health_check
        self.logger.logger.info(f"📋 Health check registered: {name} (every {interval_seconds}s)")
    
    def start_monitoring(self):
        """Start continuous monitoring"""
        if self.monitoring_active:
            self.logger.logger.warning("Monitoring already active")
            return
        
        self.monitoring_active = True
        self.stop_event.clear()
        
        # Schedule health checks
        if schedule:
            for name, check in self.health_checks.items():
                schedule.every(check.interval_seconds).seconds.do(
                    self._run_health_check, check_name=name
                )
            
            # Schedule periodic reports
            schedule.every(15).minutes.do(self._generate_health_report)
        else:
            self.logger.logger.warning("Schedule module not available - using simplified monitoring")
        
        # Start monitoring thread
        self.monitoring_thread = Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        # Setup graceful shutdown
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)
        
        self.logger.logger.info("🔍 POST-SOLUTION MONITORING STARTED")
        self.logger.logger.info(f"   Health checks: {len(self.health_checks)}")
        self.logger.logger.info(f"   Monitoring thread: {self.monitoring_thread.name}")
        
        # Generate initial health report
        self._generate_health_report()
    
    def stop_monitoring(self):
        """Stop continuous monitoring"""
        if not self.monitoring_active:
            return
        
        self.logger.logger.info("🛑 STOPPING POST-SOLUTION MONITORING")
        
        self.stop_event.set()
        self.monitoring_active = False
        
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_thread.join(timeout=5)
        
        if schedule:
            schedule.clear()
        self.logger.logger.info("   Monitoring stopped")
    
    def _monitoring_loop(self):
        """Main monitoring loop"""
        try:
            while not self.stop_event.is_set():
                if schedule:
                    schedule.run_pending()
                else:
                    # Simplified monitoring without schedule
                    self._run_simplified_monitoring()
                time.sleep(1)
        except Exception as e:
            self.logger.logger.error(f"❌ Monitoring loop error: {e}")
        finally:
            self.logger.logger.info("   Monitoring loop ended")
    
    def _run_simplified_monitoring(self):
        """Simplified monitoring without schedule module"""
        import time
        current_time = time.time()
        
        # Run basic health checks every 60 seconds
        if not hasattr(self, '_last_health_check'):
            self._last_health_check = 0
        
        if current_time - self._last_health_check > 60:
            for check_name in list(self.health_checks.keys())[:3]:  # Run first 3 checks
                try:
                    self._run_health_check(check_name)
                except Exception as e:
                    self.logger.logger.error(f"Health check {check_name} failed: {e}")
            self._last_health_check = current_time
        
        # Generate health report every 15 minutes
        if not hasattr(self, '_last_report'):
            self._last_report = 0
        
        if current_time - self._last_report > 900:  # 15 minutes
            try:
                self._generate_health_report()
            except Exception as e:
                self.logger.logger.error(f"Health report generation failed: {e}")
            self._last_report = current_time
    
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals gracefully"""
        self.logger.logger.info(f"Received signal {signum}, shutting down monitoring...")
        self.stop_monitoring()
        sys.exit(0)
    
    def _run_health_check(self, check_name: str):
        """Execute a single health check"""
        if check_name not in self.health_checks:
            return
        
        check = self.health_checks[check_name]
        
        try:
            with diagnostic_context(self.logger, f"HEALTH_CHECK_{check_name.upper()}"):
                start_time = time.time()
                
                # Run check with timeout
                import threading
                result = [None]
                exception = [None]
                
                def run_check():
                    try:
                        result[0] = check.check_function()
                    except Exception as e:
                        exception[0] = e
                
                check_thread = threading.Thread(target=run_check)
                check_thread.start()
                check_thread.join(timeout=check.timeout_seconds)
                
                if check_thread.is_alive():
                    # Check timed out
                    self._generate_alert(
                        severity="CRITICAL" if check.critical else "WARNING",
                        component=check_name,
                        message=f"Health check timed out after {check.timeout_seconds}s",
                        details={"timeout_seconds": check.timeout_seconds}
                    )
                    return
                
                if exception[0]:
                    raise exception[0]
                
                execution_time = time.time() - start_time
                check_passed = bool(result[0])
                
                if check_passed:
                    self.logger.logger.debug(f"✅ {check_name}: PASS ({execution_time:.3f}s)")
                    # Resolve any existing alerts for this check
                    self._resolve_alerts(check_name)
                else:
                    self.logger.logger.warning(f"❌ {check_name}: FAIL ({execution_time:.3f}s)")
                    self._generate_alert(
                        severity="CRITICAL" if check.critical else "WARNING",
                        component=check_name,
                        message=f"Health check failed: {check.description}",
                        details={"execution_time_seconds": execution_time}
                    )
                
        except Exception as e:
            self.logger.logger.error(f"❌ Health check {check_name} error: {e}")
            self._generate_alert(
                severity="CRITICAL" if check.critical else "WARNING",
                component=check_name,
                message=f"Health check error: {str(e)}",
                details={"error_type": type(e).__name__}
            )
    
    def _generate_alert(self, severity: str, component: str, message: str, details: Dict[str, Any]):
        """Generate and handle a monitoring alert"""
        
        alert = MonitoringAlert(
            timestamp=datetime.now(timezone.utc).isoformat(),
            alert_id=f"{component}_{int(time.time())}",
            severity=severity,
            component=component,
            message=message,
            details=details
        )
        
        self.active_alerts.append(alert)
        
        # Log alert
        log_func = self.logger.logger.critical if severity == "CRITICAL" else self.logger.logger.warning
        log_func(f"🚨 ALERT [{severity}]: {component} - {message}")
        
        # Call alert callback if configured
        if self.alert_callback:
            try:
                self.alert_callback(alert)
            except Exception as e:
                self.logger.logger.error(f"Alert callback error: {e}")
    
    def _resolve_alerts(self, component: str):
        """Resolve active alerts for a component"""
        current_time = datetime.now(timezone.utc).isoformat()
        
        for alert in self.active_alerts:
            if alert.component == component and not alert.resolved:
                alert.resolved = True
                alert.resolution_timestamp = current_time
                self.logger.logger.info(f"✅ RESOLVED: {alert.component} - {alert.message}")
    
    def _generate_health_report(self):
        """Generate comprehensive health report"""
        current_time = datetime.now(timezone.utc)
        uptime = (current_time - self.start_time).total_seconds()
        
        # Collect system metrics
        system_metrics = self.system_monitor.get_current_metrics()
        performance_metrics = {
            "cpu_percent": system_metrics.cpu_percent,
            "memory_percent": system_metrics.memory_percent,
            "disk_percent": system_metrics.disk_percent,
            "network_connections": system_metrics.network_connections
        }
        
        # Collect database metrics if available
        if self.db_monitor:
            db_metrics = self.db_monitor.test_database_connectivity()
            performance_metrics.update({
                "db_response_time_ms": db_metrics.query_response_time_ms,
                "db_connection_success": db_metrics.connection_test_success
            })
        
        # Determine component status
        component_status = {}
        overall_status = HealthStatus.HEALTHY
        
        for check_name in self.health_checks.keys():
            # Check if component has active critical alerts
            has_critical_alerts = any(
                alert.component == check_name and 
                alert.severity == "CRITICAL" and 
                not alert.resolved
                for alert in self.active_alerts
            )
            
            if has_critical_alerts:
                component_status[check_name] = HealthStatus.CRITICAL
                overall_status = HealthStatus.CRITICAL
            else:
                component_status[check_name] = HealthStatus.HEALTHY
        
        # Get active alerts only
        active_alerts = [alert for alert in self.active_alerts if not alert.resolved]
        
        # Adjust overall status based on active alerts
        if any(alert.severity == "CRITICAL" for alert in active_alerts):
            overall_status = HealthStatus.CRITICAL
        elif active_alerts:
            overall_status = HealthStatus.DEGRADED
        
        health_report = HealthReport(
            timestamp=current_time.isoformat(),
            overall_status=overall_status,
            component_status=component_status,
            active_alerts=active_alerts,
            performance_metrics=performance_metrics,
            uptime_seconds=uptime,
            last_restart=self.start_time.isoformat()
        )
        
        # Store in history
        self.health_history.append(health_report)
        if len(self.health_history) > 100:  # Keep last 100 reports
            self.health_history.pop(0)
        
        # Log health summary
        self.logger.logger.info("🏥 HEALTH REPORT GENERATED")
        self.logger.logger.info(f"   Overall Status: {overall_status.value}")
        self.logger.logger.info(f"   Active Alerts: {len(active_alerts)}")
        self.logger.logger.info(f"   Uptime: {uptime/3600:.1f} hours")
        self.logger.logger.info(f"   CPU: {system_metrics.cpu_percent}%")
        self.logger.logger.info(f"   Memory: {system_metrics.memory_percent}%")
        
        if active_alerts:
            self.logger.logger.warning("   ACTIVE ALERTS:")
            for alert in active_alerts[:5]:  # Show first 5 alerts
                self.logger.logger.warning(f"     • [{alert.severity}] {alert.component}: {alert.message}")
        
        return health_report
    
    def get_current_health(self) -> HealthReport:
        """Get current health status"""
        return self._generate_health_report()
    
    # Health check implementations
    def _check_cpu_usage(self) -> bool:
        """Check if CPU usage is within acceptable limits"""
        import psutil
        cpu_percent = psutil.cpu_percent(interval=1)
        return cpu_percent < 80.0
    
    def _check_memory_usage(self) -> bool:
        """Check if memory usage is within acceptable limits"""
        import psutil
        memory_percent = psutil.virtual_memory().percent
        return memory_percent < 85.0
    
    def _check_disk_space(self) -> bool:
        """Check if disk space is sufficient"""
        import psutil
        disk_usage = psutil.disk_usage('/').percent
        return disk_usage < 90.0
    
    def _check_database_health(self) -> bool:
        """Check database connectivity and performance"""
        if not self.db_monitor:
            return True
        
        db_metrics = self.db_monitor.test_database_connectivity()
        return (
            db_metrics.connection_test_success and 
            db_metrics.query_response_time_ms < 2000  # 2 second max
        )
    
    def _check_google_services(self) -> bool:
        """Check Google services availability"""
        google_services = self.service_monitor.monitor_google_services()
        
        # Consider healthy if at least one service is accessible
        return any(service.success for service in google_services.values())
    
    def _check_telegram_bot_health(self) -> bool:
        """Check Telegram bot health (placeholder - implement based on your bot)"""
        # This would need to be implemented based on your specific bot architecture
        # For example, checking if bot can respond to a test message
        # or if webhook is receiving updates
        return True  # Placeholder

# Flask/FastAPI endpoint for health checks
def create_health_endpoint(monitor: PostSolutionMonitor):
    """Create health check endpoint for web frameworks"""
    
    def health_check():
        """Health check endpoint"""
        try:
            health_report = monitor.get_current_health()
            
            status_code = 200
            if health_report.overall_status == HealthStatus.CRITICAL:
                status_code = 503  # Service Unavailable
            elif health_report.overall_status == HealthStatus.DEGRADED:
                status_code = 200  # OK but with warnings
            
            return {
                "status": health_report.overall_status.value.lower(),
                "timestamp": health_report.timestamp,
                "uptime_seconds": health_report.uptime_seconds,
                "components": {
                    name: status.value.lower() 
                    for name, status in health_report.component_status.items()
                },
                "metrics": health_report.performance_metrics,
                "active_alerts": len(health_report.active_alerts)
            }, status_code
            
        except Exception as e:
            return {
                "status": "error",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "error": str(e)
            }, 500
    
    return health_check

# Context manager for temporary monitoring
@contextmanager
def temporary_monitoring(
    logger: DiagnosticLogger,
    duration_minutes: int = 60,
    db_engine=None,
    alert_callback=None
):
    """Context manager for temporary post-solution monitoring"""
    monitor = PostSolutionMonitor(logger, db_engine, alert_callback)
    
    try:
        monitor.start_monitoring()
        logger.logger.info(f"🔍 Temporary monitoring started for {duration_minutes} minutes")
        
        # Wait for specified duration
        time.sleep(duration_minutes * 60)
        
        yield monitor
        
    finally:
        monitor.stop_monitoring()
        
        # Generate final report
        final_report = monitor.get_current_health()
        logger.logger.info("📊 FINAL MONITORING REPORT:")
        logger.logger.info(f"   Duration: {duration_minutes} minutes")
        logger.logger.info(f"   Final Status: {final_report.overall_status.value}")
        logger.logger.info(f"   Total Alerts: {len(monitor.active_alerts)}")